---
title: "Us vs AI"
date: "2026-01-13"
---

I recently attended a lot of talks by scientists from all over, from FAANG companies, and this is my thought and take on current AI systems and how their future looks. And how we should go along with this fast-paced AI race. I myself am a student and am constantly adapting to this everyday-changing field, and this is my take on it. Here, I also refrain from using some complex terms like awareness, consciousness, etc., whose meanings I do not know clearly.

AI is not yet perfect; there are many things current AI systems lack, and we humans are better at them. As AI is trained on the internet, the internet is not what humans are, but what humans want to put out there for others. The internet lacks a lot of data about nature and life, and that makes us better than current AI systems in:

- Sense of space  
- Sense of time  
- Sense of embodiment  
- Ethics  
- Curiosity → leads to very little original work
- Efficiency of our brains (both memory and compute) -> An overall subject in itself.

## Sense of 3D Space and Time
Current models are bad at understanding and predicting the softness or hardness of objects, the density of things, the spatial volume of things, and what a kilometer actually is and how much an hour actually feels like. This problem arises due to the unavailability of data from appropriate sensors. There are teams trying to understand and build models which are called *world models*, which can understand the world; this involves understanding time and space.

This involves studying effective means of dimensionality reduction, generating relevant data, and creating models which can understand basic physics and predict the trajectories of moving objects. This requires models to have a sense of time. We humans have multiple layers of understanding of time, and I feel it is much harder to achieve without clear definitions and study of it. (I may not be aware of any such study, but there has been a lot of work on animal circadian rhythms and menstrual cycles and growth phases, which are a representation of how our body and brain understand time.) (There has also been a lot of study in neuroscience on mice and their understanding of 3D space.)

Studying this is important to make models that can be used by robots to make them move and predict the movement of objects around them for smooth motion. These robots may perform surgeries in the future, where they will need a sense of rigidity—how hard to hold a scissor versus a layer of skin. Self-driving cars and the AI models behind them need an understanding of cars moving around them, how far they are, and what is a safe distance to maintain. (This may overlap with work already done in self-driving cars and VR setups, but this is only going to improve upon it.)

This later brings in the sense of embodiment—the sense of owning the body and being able to act through it. Robotic systems will have more understanding of the limitations and capacity of their bodies and will further learn to perform required tasks within constrained limits.

A lot of my understanding comes from a talk by Prof. Srinath Sridhar at IISER Pune recently. I personally found his work very inspiring; please find more at [text](https://ivl.cs.brown.edu/).

## Thoughts, Ethics, and Curiosity

This portion is completely my understanding and not much research-proven; I will try to mention wherever possible. I think of the brain as analogous to neural networks, maybe with more complex dynamics than ours. I will take the example of AlexNet, which is made from multiple layers of CNNs. There have been works making analogies with the visual cortex, where initial layers learn to identify simple patterns like edges and curves, further deeper layers learn to identify eyes, whiskers, and tails, and the deepest layers identify faces.

**[Hypothesis]** Similarly, I believe the brain's speech centers (Broca's area (speech production, frontal lobe) and Wernicke's area) which generate speech have an even deeper component that generates randomness, which leads to the generation of thoughts later converted into our understandable language or visuals by our visual cortex and speech centers. As these thoughts originate from randomness but are later passed through a network trained on vision and language data, our brain tries to find meaning or sense from them, and the part of the network trained for values and ethics from experience and upbringing tries to tame those thoughts.

Slowly, we begin to generate good thoughts, and thoughts can be questions, which could be the source of our creativity. What if I could do it this way? What if I move ahead to convert a yorker to a full-toss? This curiosity leads to the generation of hypotheses, and their further proof leads to the generation of science and mathematics and language and politics, etc.

Though this is a hypothesis, it is worth trying. Our current chatbots have a part that learns ethics by brute force and has a representation of emotions but do not have their own thoughts and curiosity.

## How to keep up?

As a student of the field, my response is always a mix of my own thoughts and my professors'. This is Prof. Udyaan’s take on it: *"When we ask these chatbots questions, we are training the next versions of the models; we should rather make the models ask questions and find the answers."* I think with the emergence of chatbots there is an emergence of a global language, a global English, where everyone uses similar words, and words like "dwell," "delve," "navigate," etc., which we did not use on a daily basis before. This shows a loss of creativity in language and our direction toward moving to a more optimized language for communication.

The curse of optimization, as Naval's view states, is that *"Good products are hard to vary."* A saying by Antoine de Saint-Exupéry is, *"The airplane wing is perfect not because there is nothing to add but because there is nothing to remove."* This curse of optimization has led us all to have very similar-looking cars and phones like iPhones. Even Apple and its competitors have tried to change the form factor of the product but could not. That is an ideal product, and slowly even languages are also on the track of optimization.

There are a lot of companies currently trying to make AI open-source in the hope of democratizing it and making it more personalized by our data. But what if we do not have any of our own data? Generating data like text and art from our own creativity is still useful even for upcoming AI systems to be personalized. We should use AI like calculators—not while learning multiplication, but when we have learned it and are building upon it.

This advent cannot be stopped; we have to adapt around it. Yes, we will lose a lot of things, as people lost the ability to solve basic math after the advent of calculators. But does that make us weak at math? No—we have only been building upon it. We now have intelligent systems in our pockets which we need to use, learn to use, and understand their limitations, and keep building over them. But we did not stop teaching our kids multiplication even after the advent of calculators; similarly, we should not stop here.
